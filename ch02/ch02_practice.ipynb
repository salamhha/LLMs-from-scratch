{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21a4c56b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:tornado.general:Uncaught exception in ZMQStream callback\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/traitlets/traitlets.py\", line 632, in get\n",
      "    value = obj._trait_values[self.name]\n",
      "            ~~~~~~~~~~~~~~~~~^^^^^^^^^^^\n",
      "KeyError: '_control_lock'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/zmq/eventloop/zmqstream.py\", line 565, in _log_error\n",
      "    f.result()\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 340, in dispatch_control\n",
      "    async with self._control_lock:\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/traitlets/traitlets.py\", line 687, in __get__\n",
      "    return t.cast(G, self.get(obj, cls))  # the G should encode the Optional\n",
      "                     ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/traitlets/traitlets.py\", line 649, in get\n",
      "    value = self._validate(obj, default)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/traitlets/traitlets.py\", line 722, in _validate\n",
      "    value = self.validate(obj, value)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/traitlets/traitlets.py\", line 2311, in validate\n",
      "    self.error(obj, value)\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/traitlets/traitlets.py\", line 831, in error\n",
      "    raise TraitError(e)\n",
      "traitlets.traitlets.TraitError: The '_control_lock' trait of an IPythonKernel instance expected a Lock, not the NoneType None.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "if not os.path.exists(\"the-verdict.txt\"):\n",
    "    url = (\n",
    "        \"https://raw.githubusercontent.com/rasbt/\"\n",
    "        \"LLMs-from-scratch/main/ch02/01_main-chapter-code/\"\n",
    "        \"the-verdict.txt\"\n",
    "    )\n",
    "    file_path = \"the-verdict.txt\"\n",
    "\n",
    "    response = requests.get(url, timeout=30)\n",
    "    response.raise_for_status()\n",
    "    with open(file_path, \"wb\") as f:\n",
    "        f.write(response.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28d5824d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of character: 20479\n",
      "I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no \n"
     ]
    }
   ],
   "source": [
    "with open(\"the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_text = f.read()\n",
    "    \n",
    "print(\"Total number of character:\", len(raw_text))\n",
    "print(raw_text[:99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c201e46c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello,', ' ', 'world.', ' ', 'This', ' ', 'is', ' ', 'a', ' ', 'test.']\n"
     ]
    }
   ],
   "source": [
    "import re \n",
    "text = \"Hello, world. This is a test.\"\n",
    "result = re.split(r'(\\s)', text)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "381a7491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', ',', '', ' ', 'world', '.', '', ' ', 'This', ' ', 'is', ' ', 'a', ' ', 'test', '.', '']\n"
     ]
    }
   ],
   "source": [
    "result = re.split(r'([,.]|\\s)', text)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a3c8a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', ',', 'world', '.', 'This', 'is', 'a', 'test', '.']\n"
     ]
    }
   ],
   "source": [
    "# Strip whitespace and remove emtpy strings\n",
    "result = [item for item in result if item.strip()]\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e1a3b54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', ',', 'world', '.', 'Is', 'this', '--', 'a', 'test', '?']\n"
     ]
    }
   ],
   "source": [
    "text = \"Hello, world. Is this-- a test?\"\n",
    "\n",
    "result = re.split(r'([,.:;?+!\"()\\']|--|\\s)', text)\n",
    "result = [item.strip() for item in result if item.strip()]\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9a54bd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'HAD', 'always', 'thought', 'Jack', 'Gisburn', 'rather', 'a', 'cheap', 'genius', '--', 'though', 'a', 'good', 'fellow', 'enough', '--', 'so', 'it', 'was', 'no', 'great', 'surprise', 'to', 'me', 'to', 'hear', 'that', ',', 'in']\n"
     ]
    }
   ],
   "source": [
    "preprocessed = re.split(r'([,.:;?_!\"()\\']|--|\\s)', raw_text)\n",
    "preprocessed = [item.strip() for item in preprocessed if item.strip()]\n",
    "print(preprocessed[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70ee1a7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4690\n"
     ]
    }
   ],
   "source": [
    "print(len(preprocessed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f497d85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1130\n"
     ]
    }
   ],
   "source": [
    "all_words = sorted(set(preprocessed))\n",
    "vocab_size = len(all_words)\n",
    "\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e26a32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {token:integer for integer,token in enumerate(all_words)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14eb9c3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('!', 0)\n",
      "('\"', 1)\n",
      "(\"'\", 2)\n",
      "('(', 3)\n",
      "(')', 4)\n",
      "(',', 5)\n",
      "('--', 6)\n",
      "('.', 7)\n",
      "(':', 8)\n",
      "(';', 9)\n",
      "('?', 10)\n",
      "('A', 11)\n",
      "('Ah', 12)\n",
      "('Among', 13)\n",
      "('And', 14)\n",
      "('Are', 15)\n",
      "('Arrt', 16)\n",
      "('As', 17)\n",
      "('At', 18)\n",
      "('Be', 19)\n",
      "('Begin', 20)\n",
      "('Burlington', 21)\n",
      "('But', 22)\n",
      "('By', 23)\n",
      "('Carlo', 24)\n",
      "('Chicago', 25)\n",
      "('Claude', 26)\n",
      "('Come', 27)\n",
      "('Croft', 28)\n",
      "('Destroyed', 29)\n",
      "('Devonshire', 30)\n",
      "('Don', 31)\n",
      "('Dubarry', 32)\n",
      "('Emperors', 33)\n",
      "('Florence', 34)\n",
      "('For', 35)\n",
      "('Gallery', 36)\n",
      "('Gideon', 37)\n",
      "('Gisburn', 38)\n",
      "('Gisburns', 39)\n",
      "('Grafton', 40)\n",
      "('Greek', 41)\n",
      "('Grindle', 42)\n",
      "('Grindles', 43)\n",
      "('HAD', 44)\n",
      "('Had', 45)\n",
      "('Hang', 46)\n",
      "('Has', 47)\n",
      "('He', 48)\n",
      "('Her', 49)\n",
      "('Hermia', 50)\n"
     ]
    }
   ],
   "source": [
    "for i, item in enumerate(vocab.items()):\n",
    "    print(item)\n",
    "    if i >= 50:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83311b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a tokenizer class\n",
    "class SimpleTokenizerV1:\n",
    "    def __init__(self, vocab):\n",
    "        self.str_to_int = vocab\n",
    "        self.int_to_str = {i:s for s,i in vocab.items()}\n",
    "    \n",
    "    def encode(self, text):\n",
    "        preprocessed = re.split(r'([,.:;?_!\"()\\']|--|\\s)', text)\n",
    "                                \n",
    "        preprocessed = [\n",
    "            item.strip() for item in preprocessed if item.strip()\n",
    "        ]\n",
    "        ids = [self.str_to_int[s] for s in preprocessed]\n",
    "        return ids\n",
    "        \n",
    "    def decode(self, ids):\n",
    "        text = \" \".join([self.int_to_str[i] for i in ids])\n",
    "        # Replace spaces before the specified punctuations\n",
    "        text = re.sub(r'\\s+([,.?!\"()\\'])', r'\\1', text)\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "46ee6b7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 56, 2, 850, 988, 602, 533, 746, 5, 1126, 596, 5, 1, 67, 7, 38, 851, 1108, 754, 793, 7]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = SimpleTokenizerV1(vocab)\n",
    "text = \"\"\"\"It's the last he painted, you know,\" \n",
    "           Mrs. Gisburn said with pardonable pride.\"\"\"\n",
    "\n",
    "ids = tokenizer.encode(text)\n",
    "print(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b83d81e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\" It\\' s the last he painted, you know,\" Mrs. Gisburn said with pardonable pride.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "19382889",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\" It\\' s the last he painted, you know,\" Mrs. Gisburn said with pardonable pride.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenizer.encode(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "855e8af1",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Hello'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      2\u001b[39m tokenizer = SimpleTokenizerV1(vocab)\n\u001b[32m      4\u001b[39m text = \u001b[33m\"\u001b[39m\u001b[33mHello, do you like tea. Is this-- a test?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[43mtokenizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 13\u001b[39m, in \u001b[36mSimpleTokenizerV1.encode\u001b[39m\u001b[34m(self, text)\u001b[39m\n\u001b[32m      8\u001b[39m preprocessed = re.split(\u001b[33mr\u001b[39m\u001b[33m'\u001b[39m\u001b[33m([,.:;?_!\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m()\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[33m]|--|\u001b[39m\u001b[33m\\\u001b[39m\u001b[33ms)\u001b[39m\u001b[33m'\u001b[39m, text)\n\u001b[32m     10\u001b[39m preprocessed = [\n\u001b[32m     11\u001b[39m     item.strip() \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m preprocessed \u001b[38;5;28;01mif\u001b[39;00m item.strip()\n\u001b[32m     12\u001b[39m ]\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m ids = [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstr_to_int\u001b[49m\u001b[43m[\u001b[49m\u001b[43ms\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m preprocessed]\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m ids\n",
      "\u001b[31mKeyError\u001b[39m: 'Hello'"
     ]
    }
   ],
   "source": [
    "# Tokenizing unknown text\n",
    "tokenizer = SimpleTokenizerV1(vocab)\n",
    "\n",
    "text = \"Hello, do you like tea. Is this-- a test?\"\n",
    "\n",
    "tokenizer.encode(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "946799a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tokens = sorted(list(set(preprocessed)))\n",
    "all_tokens.extend([\"<|endoftext|>\", \"<|unk|>\"])\n",
    "\n",
    "vocab = {token:integer for integer,token in enumerate(all_tokens)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "53fafcb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1132"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "11ce340e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('younger', 1127)\n",
      "('your', 1128)\n",
      "('yourself', 1129)\n",
      "('<|endoftext|>', 1130)\n",
      "('<|unk|>', 1131)\n"
     ]
    }
   ],
   "source": [
    "for i, item in enumerate(list(vocab.items())[-5:]):\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4e007b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleTokenizerV2:\n",
    "    def __init__(self, vocab):\n",
    "        self.str_to_int = vocab\n",
    "        self.int_to_str = { i:s for s,i in vocab.items()}\n",
    "    \n",
    "    def encode(self, text):\n",
    "        preprocessed = re.split(r'([,.:;?_!\"()\\']|--|\\s)', text)\n",
    "        preprocessed = [item.strip() for item in preprocessed if item.strip()]\n",
    "        preprocessed = [\n",
    "            item if item in self.str_to_int\n",
    "            else \"<|unk|>\" for item in preprocessed\n",
    "        ]\n",
    "\n",
    "        ids = [self.str_to_int[s] for s in preprocessed]\n",
    "        return ids\n",
    "\n",
    "    def decode(self, ids):\n",
    "        text = \" \".join([self.int_to_str[i] for i in ids])\n",
    "        # Replace spaces before punctuation\n",
    "        text = re.sub(r'\\s+([,.:;?!\"()\\'])', r'\\1', text)\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d02e88d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, do you like tea? <|endoftext|> In the sunlit terraces of the palace.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = SimpleTokenizerV2(vocab)\n",
    "\n",
    "text1 = \"Hello, do you like tea?\"\n",
    "text2 = \"In the sunlit terraces of the palace.\"\n",
    "\n",
    "text = \" <|endoftext|> \".join((text1, text2))\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ec59a5b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1131, 5, 355, 1126, 628, 975, 10, 1130, 55, 988, 956, 984, 722, 988, 1131, 7]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f855cded",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|unk|>, do you like tea? <|endoftext|> In the sunlit terraces of the <|unk|>.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenizer.encode(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "54240318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tiktoken in /home/codespace/.local/lib/python3.12/site-packages (0.12.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /home/codespace/.local/lib/python3.12/site-packages (from tiktoken) (2025.11.3)\n",
      "Requirement already satisfied: requests>=2.26.0 in /home/codespace/.local/lib/python3.12/site-packages (from tiktoken) (2.32.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/codespace/.local/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/codespace/.local/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken) (2025.10.5)\n"
     ]
    }
   ],
   "source": [
    "# BytePair encoding\n",
    "!pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ec3d09c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tiktoken version: 0.12.0\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import tiktoken\n",
    "\n",
    "print(\"tiktoken version:\", importlib.metadata.version(\"tiktoken\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fa74b30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f055de19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15496, 11, 466, 345, 588, 8887, 30, 220, 50256, 554, 262, 4252, 18250, 8812, 2114, 1659, 617, 34680, 27271, 13]\n"
     ]
    }
   ],
   "source": [
    "text = (\n",
    "    \"Hello, do you like tea? <|endoftext|> In the sunlit terraces\"\n",
    "     \"of someunknownPlace.\"\n",
    ")\n",
    "\n",
    "integers = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n",
    "\n",
    "print(integers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "83837a13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, do you like tea? <|endoftext|> In the sunlit terracesof someunknownPlace.\n"
     ]
    }
   ],
   "source": [
    "strings = tokenizer.decode(integers)\n",
    "\n",
    "print(strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ce06c6c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5145\n"
     ]
    }
   ],
   "source": [
    "# Data sampling with sliding window\n",
    "with open(\"the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_text = f.read()\n",
    "\n",
    "enc_text = tokenizer.encode(raw_text)\n",
    "print(len(enc_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "43b66624",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_sample = enc_text[50:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d00ba2b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: [290, 4920, 2241, 287]\n",
      "y:      [4920, 2241, 287, 257]\n"
     ]
    }
   ],
   "source": [
    "context_size = 4\n",
    "\n",
    "x = enc_sample[:context_size]\n",
    "y = enc_sample[1:context_size+1]\n",
    "\n",
    "print(f\"x: {x}\")\n",
    "print(f\"y:      {y}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6ed639df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[290] ----> 4920\n",
      "[290, 4920] ----> 2241\n",
      "[290, 4920, 2241] ----> 287\n",
      "[290, 4920, 2241, 287] ----> 257\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, context_size+1):\n",
    "    context = enc_sample[:i]\n",
    "    desired = enc_sample[i]\n",
    "    print(context, \"---->\", desired)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4577d11a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " and ---->  established\n",
      " and established ---->  himself\n",
      " and established himself ---->  in\n",
      " and established himself in ---->  a\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, context_size+1):\n",
    "    context = enc_sample[:i]\n",
    "    desired = enc_sample[i]\n",
    "\n",
    "    print(tokenizer.decode(context), \"---->\", tokenizer.decode([desired]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3750aee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "589b72a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class GPTDatasetV1(Dataset):\n",
    "    def __init__(self, txt, tokenizer, max_length, stride):\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "\n",
    "        # Tokenize the entire text\n",
    "        token_ids = tokenizer.encode(txt, allowed_special={\"<|endoftext|>\"})\n",
    "        assert len(token_ids) > max_length, \"Number of tokenized inputs must be at least equal to max_length+1\"\n",
    "\n",
    "        # Use a sliding window to chunk the book into overlapping sequences\n",
    "        for i in range(0, len(token_ids) - max_length, stride):\n",
    "            input_chunk = token_ids[i:i+max_length]\n",
    "            target_chunk = token_ids[i+1:i+max_length+1]\n",
    "            self.input_ids.append(torch.tensor(input_chunk))\n",
    "            self.target_ids.append(torch.tensor(target_chunk))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.target_ids[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e1fc6df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloader_v1(txt, batch_size=4, max_length=256,\n",
    "                        stride=128, shuffle=True, drop_last=True, num_workers=0):\n",
    "    \n",
    "    # Initialize tokenizer\n",
    "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "    # Create dataset\n",
    "    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
    "\n",
    "    # Create dataloader\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        drop_last=drop_last,\n",
    "        num_workers=num_workers\n",
    "    )\n",
    "\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dd4d7bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ff29683c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[  40,  367, 2885, 1464]]), tensor([[ 367, 2885, 1464, 1807]])]\n"
     ]
    }
   ],
   "source": [
    "dataloader = create_dataloader_v1(\n",
    "    raw_text, batch_size=1, max_length=4, stride=1, shuffle=False\n",
    ")\n",
    "\n",
    "data_iter = iter(dataloader)\n",
    "first_batch = next(data_iter)\n",
    "print(first_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7135d47b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[ 367, 2885, 1464, 1807]]), tensor([[2885, 1464, 1807, 3619]])]\n"
     ]
    }
   ],
   "source": [
    "second_batch = next(data_iter)\n",
    "print(second_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8e3f7b05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs:\n",
      " tensor([[   40,   367,  2885,  1464],\n",
      "        [ 1807,  3619,   402,   271],\n",
      "        [10899,  2138,   257,  7026],\n",
      "        [15632,   438,  2016,   257],\n",
      "        [  922,  5891,  1576,   438],\n",
      "        [  568,   340,   373,   645],\n",
      "        [ 1049,  5975,   284,   502],\n",
      "        [  284,  3285,   326,    11]])\n",
      "\n",
      "Targets:\n",
      " tensor([[  367,  2885,  1464,  1807],\n",
      "        [ 3619,   402,   271, 10899],\n",
      "        [ 2138,   257,  7026, 15632],\n",
      "        [  438,  2016,   257,   922],\n",
      "        [ 5891,  1576,   438,   568],\n",
      "        [  340,   373,   645,  1049],\n",
      "        [ 5975,   284,   502,   284],\n",
      "        [ 3285,   326,    11,   287]])\n"
     ]
    }
   ],
   "source": [
    "dataloader = create_dataloader_v1(raw_text, batch_size=8, max_length=4, stride=4, shuffle=False)\n",
    "\n",
    "data_iter = iter(dataloader)\n",
    "inputs, targets = next(data_iter)\n",
    "print(\"Inputs:\\n\", inputs)\n",
    "print(\"\\nTargets:\\n\", targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a3ba859e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding vectors\n",
    "input_ids = torch.tensor([2, 3, 5, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c177bcf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 6\n",
    "output_dim = 3\n",
    "\n",
    "torch.manual_seed(123)\n",
    "embedding_layer = torch.nn.Embedding(vocab_size, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e6f98cc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.3374, -0.1778, -0.1690],\n",
      "        [ 0.9178,  1.5810,  1.3010],\n",
      "        [ 1.2753, -0.2010, -0.1606],\n",
      "        [-0.4015,  0.9666, -1.1481],\n",
      "        [-1.1589,  0.3255, -0.6315],\n",
      "        [-2.8400, -0.7849, -1.4096]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(embedding_layer.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "16a3bfde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.4015,  0.9666, -1.1481]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(embedding_layer(torch.tensor([3])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2b0c6fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.2753, -0.2010, -0.1606],\n",
      "        [-0.4015,  0.9666, -1.1481],\n",
      "        [-2.8400, -0.7849, -1.4096],\n",
      "        [ 0.9178,  1.5810,  1.3010]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(embedding_layer(input_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "21abf005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enoding word positions\n",
    "vocab_size = 50257\n",
    "output_dim = 256\n",
    "token_embedding_layer = torch.nn.Embedding(vocab_size, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c711d493",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 4\n",
    "dataloader = create_dataloader_v1(\n",
    "    raw_text, batch_size = 8, max_length=max_length,\n",
    "    stride=max_length, shuffle=False\n",
    ")\n",
    "data_iter = iter(dataloader)\n",
    "inputs, targets = next(data_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a5751cc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs:\n",
      " tensor([[   40,   367,  2885,  1464],\n",
      "        [ 1807,  3619,   402,   271],\n",
      "        [10899,  2138,   257,  7026],\n",
      "        [15632,   438,  2016,   257],\n",
      "        [  922,  5891,  1576,   438],\n",
      "        [  568,   340,   373,   645],\n",
      "        [ 1049,  5975,   284,   502],\n",
      "        [  284,  3285,   326,    11]])\n",
      "\n",
      "Inputs shape:\n",
      " torch.Size([8, 4])\n"
     ]
    }
   ],
   "source": [
    "print(\"Token IDs:\\n\", inputs)\n",
    "print(\"\\nInputs shape:\\n\", inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8ff22b11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 4, 256])\n",
      "tensor([[[ 1.4588, -0.3653, -0.0404,  ..., -0.1445,  0.3833,  0.3091],\n",
      "         [-0.2655, -0.2798, -2.5196,  ..., -1.1844,  2.7038,  0.9186],\n",
      "         [ 0.6687,  0.7299,  0.3889,  ..., -0.0528,  0.0065, -1.1664],\n",
      "         [ 1.6191,  0.9051, -0.4884,  ...,  0.3483, -0.6136,  0.3884]],\n",
      "\n",
      "        [[-0.7848,  0.0632, -0.3674,  ..., -0.3421, -0.4469, -1.5079],\n",
      "         [-0.3812, -0.5149,  0.1585,  ...,  0.6091,  0.0865,  0.4503],\n",
      "         [-0.1415,  1.5888,  0.0494,  ...,  1.4478, -0.3205,  1.4569],\n",
      "         [-1.6207, -0.8156, -0.3197,  ...,  0.3969,  0.8440,  0.0444]],\n",
      "\n",
      "        [[ 0.1663, -0.8918,  3.2887,  ...,  0.7426, -0.5492,  2.1841],\n",
      "         [ 1.2922,  1.1209, -0.9461,  ...,  0.3205, -0.2395, -0.9524],\n",
      "         [ 0.5750,  0.0232, -0.1438,  ..., -0.3635, -0.1418,  1.2569],\n",
      "         [ 0.5686,  0.3034,  1.3640,  ...,  0.8473, -1.2123, -0.6241]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-2.6437,  0.7465,  0.2959,  ...,  1.6383, -0.0200, -0.6255],\n",
      "         [-1.3163, -1.2242,  0.4636,  ...,  0.9747,  0.0265,  1.0678],\n",
      "         [ 0.1980, -0.5273,  1.3175,  ...,  1.6292,  0.0420,  1.7706],\n",
      "         [-1.3787, -0.9402,  2.0697,  ..., -0.0573, -1.1512,  0.8685]],\n",
      "\n",
      "        [[ 1.7173,  0.2308, -1.9020,  ...,  1.5258, -0.1378, -0.9871],\n",
      "         [ 0.4416, -0.2437, -0.4828,  ...,  1.8755,  2.0836,  1.4659],\n",
      "         [ 1.3579,  0.8763,  0.0853,  ..., -1.1816, -0.3708,  0.8677],\n",
      "         [-1.5170, -0.4124,  0.8056,  ..., -0.1398,  0.1930, -1.3077]],\n",
      "\n",
      "        [[ 1.3579,  0.8763,  0.0853,  ..., -1.1816, -0.3708,  0.8677],\n",
      "         [-1.0296, -2.0113, -0.7363,  ..., -0.1128, -0.0412, -0.5161],\n",
      "         [ 2.0722,  0.5983,  0.7414,  ..., -0.3002,  0.8036, -0.9968],\n",
      "         [-0.2195,  0.6762,  1.1471,  ..., -0.0700,  1.5887,  0.2592]]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "token_embeddings = token_embedding_layer(inputs)\n",
    "print(token_embeddings.shape)\n",
    "\n",
    "print(token_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e3788c85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.6303, -0.4848, -0.1366,  ...,  1.0345, -0.5012,  1.1045],\n",
      "        [ 0.2062,  0.6078,  0.7187,  ..., -0.4628, -0.2319,  1.1980],\n",
      "        [ 0.5806, -1.3846,  0.3266,  ...,  0.8579,  0.5059,  1.0243],\n",
      "        [ 1.4323,  0.2217,  0.8599,  ...,  0.4827,  0.8459,  1.3038]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "context_length = max_length\n",
    "pos_embedding_layer = torch.nn.Embedding(context_length, output_dim)\n",
    "\n",
    "print(pos_embedding_layer.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f8c6adff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 256])\n",
      "tensor([[-0.6303, -0.4848, -0.1366,  ...,  1.0345, -0.5012,  1.1045],\n",
      "        [ 0.2062,  0.6078,  0.7187,  ..., -0.4628, -0.2319,  1.1980],\n",
      "        [ 0.5806, -1.3846,  0.3266,  ...,  0.8579,  0.5059,  1.0243],\n",
      "        [ 1.4323,  0.2217,  0.8599,  ...,  0.4827,  0.8459,  1.3038]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "pos_embeddings = pos_embedding_layer(torch.arange(max_length))\n",
    "print(pos_embeddings.shape)\n",
    "\n",
    "print(pos_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8aee1467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 4, 256])\n",
      "tensor([[[ 0.8286, -0.8501, -0.1770,  ...,  0.8900, -0.1178,  1.4135],\n",
      "         [-0.0593,  0.3280, -1.8009,  ..., -1.6473,  2.4719,  2.1166],\n",
      "         [ 1.2494, -0.6547,  0.7155,  ...,  0.8051,  0.5124, -0.1421],\n",
      "         [ 3.0514,  1.1268,  0.3715,  ...,  0.8310,  0.2323,  1.6922]],\n",
      "\n",
      "        [[-1.4150, -0.4216, -0.5040,  ...,  0.6924, -0.9481, -0.4034],\n",
      "         [-0.1750,  0.0929,  0.8772,  ...,  0.1462, -0.1454,  1.6482],\n",
      "         [ 0.4391,  0.2042,  0.3760,  ...,  2.3057,  0.1854,  2.4812],\n",
      "         [-0.1884, -0.5939,  0.5403,  ...,  0.8796,  1.6899,  1.3482]],\n",
      "\n",
      "        [[-0.4640, -1.3766,  3.1521,  ...,  1.7771, -1.0504,  3.2886],\n",
      "         [ 1.4984,  1.7287, -0.2273,  ..., -0.1423, -0.4714,  0.2455],\n",
      "         [ 1.1556, -1.3614,  0.1828,  ...,  0.4944,  0.3641,  2.2812],\n",
      "         [ 2.0009,  0.5250,  2.2239,  ...,  1.3300, -0.3664,  0.6797]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-3.2740,  0.2617,  0.1593,  ...,  2.6728, -0.5211,  0.4790],\n",
      "         [-1.1101, -0.6165,  1.1823,  ...,  0.5118, -0.2054,  2.2657],\n",
      "         [ 0.7786, -1.9119,  1.6441,  ...,  2.4871,  0.5478,  2.7949],\n",
      "         [ 0.0536, -0.7185,  2.9297,  ...,  0.4254, -0.3053,  2.1723]],\n",
      "\n",
      "        [[ 1.0871, -0.2540, -2.0386,  ...,  2.5603, -0.6390,  0.1174],\n",
      "         [ 0.6478,  0.3641,  0.2359,  ...,  1.4126,  1.8517,  2.6639],\n",
      "         [ 1.9386, -0.5083,  0.4119,  ..., -0.3237,  0.1350,  1.8920],\n",
      "         [-0.0847, -0.1908,  1.6655,  ...,  0.3429,  1.0389, -0.0039]],\n",
      "\n",
      "        [[ 0.7277,  0.3915, -0.0513,  ..., -0.1471, -0.8720,  1.9722],\n",
      "         [-0.8234, -1.4035, -0.0175,  ..., -0.5756, -0.2731,  0.6819],\n",
      "         [ 2.6528, -0.7863,  1.0679,  ...,  0.5577,  1.3094,  0.0275],\n",
      "         [ 1.2128,  0.8978,  2.0071,  ...,  0.4127,  2.4346,  1.5630]]],\n",
      "       grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "input_embeddings = token_embeddings + pos_embeddings\n",
    "print(input_embeddings.shape)\n",
    "\n",
    "print(input_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a343bd0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
